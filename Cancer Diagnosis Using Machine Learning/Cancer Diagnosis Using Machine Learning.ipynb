{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Homework1.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGuLnQbic3Tz",
        "colab_type": "text"
      },
      "source": [
        "# Homework1\n",
        "## Cancer Diagnosis Using Machine Learning\n",
        "## Harshil Patel (306646748)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_duY8zBzc3T1",
        "colab_type": "text"
      },
      "source": [
        "Write and submit your python codes in “Jupyter Notebook” to perform the following tasks. Make sure to provide proper descriptions as MarkDown for each section of your code.\n",
        "In this homework, we again work with a real dataset from UCI Dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eua6dNU8c3T3",
        "colab_type": "text"
      },
      "source": [
        "a- Read the dataset file “Cancer.csv” (from github using the following command), and assign it to a Pandas DataFrame:\n",
        "df = pd.read_csv(\"https://github.com/mpourhoma/CS4662/raw/master/Cancer.csv\") Check out the dataset. As you see, the dataset includes 9 numerical features. The last column is the binary label (“1” means it is a malignant cancer, “0” means it is a benign tumor). You will use all 9 features in this homework."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2ANu24Pc3T4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "5563dd23-8420-42e4-9c89-5bb8fb4a23e0"
      },
      "source": [
        "import pandas as pd # import package panda and save as pd\n",
        "\n",
        "Cancer_df = pd.read_csv('https://github.com/mpourhoma/CS4662/raw/master/Cancer.csv') # reading a CSV file directly from Local device, and save as df\n",
        "\n",
        "Cancer_df"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clump_Thickness</th>\n",
              "      <th>Uniformity_of_Cell_Size</th>\n",
              "      <th>Uniformity_of_Cell_Shape</th>\n",
              "      <th>Marginal_Adhesion</th>\n",
              "      <th>Single_Epithelial_Cell_Size</th>\n",
              "      <th>Bare_Nuclei</th>\n",
              "      <th>Bland_Chromatin</th>\n",
              "      <th>Normal_Nucleoli</th>\n",
              "      <th>Mitoses</th>\n",
              "      <th>Malignant_Cancer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Clump_Thickness  Uniformity_of_Cell_Size  ...  Mitoses  Malignant_Cancer\n",
              "0                  5                        1  ...        1                 0\n",
              "1                  5                        4  ...        1                 0\n",
              "2                  3                        1  ...        1                 0\n",
              "3                  6                        8  ...        1                 0\n",
              "4                  4                        1  ...        1                 0\n",
              "..               ...                      ...  ...      ...               ...\n",
              "145                3                        1  ...        1                 0\n",
              "146                9                        7  ...        3                 1\n",
              "147               10                        8  ...        1                 1\n",
              "148                1                        1  ...        1                 0\n",
              "149                5                        1  ...        1                 0\n",
              "\n",
              "[150 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5avh_89Pc3T-",
        "colab_type": "text"
      },
      "source": [
        "b- Use sklearn functions to split the dataset into testing and training sets with the following parameters: test_size=0.3, random_state=2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnCP6IWJc3T_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "c03d7f50-89bb-4e6b-ec57-1c9225bfd122"
      },
      "source": [
        "# Creating Feature Matrix\n",
        "feature_cols = ['Clump_Thickness', 'Uniformity_of_Cell_Size', 'Uniformity_of_Cell_Shape', 'Marginal_Adhesion', 'Single_Epithelial_Cell_Size', 'Bare_Nuclei', 'Bland_Chromatin', 'Normal_Nucleoli', 'Mitoses']\n",
        "\n",
        "\n",
        "A = Cancer_df[feature_cols]\n",
        "    \n",
        "print(A.shape)\n",
        "\n",
        "f = Cancer_df['Malignant_Cancer'] \n",
        "print(f)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 9)\n",
            "0      0\n",
            "1      0\n",
            "2      0\n",
            "3      0\n",
            "4      0\n",
            "      ..\n",
            "145    0\n",
            "146    1\n",
            "147    1\n",
            "148    0\n",
            "149    0\n",
            "Name: Malignant_Cancer, Length: 150, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1PyjQn6c3UC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "A_train,A_test,f_train,f_test = train_test_split (A, f, test_size=0.3, random_state=2) #split the data basis on"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PAoqAGVc3UE",
        "colab_type": "text"
      },
      "source": [
        "c- Use “Decision Tree Classifier” to predict Cancer based on the training/testing datasets that you built in part (h). Then, calculate and report the accuracy and AUC of your classifier. Later in part (g), you will plot the ROC curve as well. Use this command to define your tree: my_DecisionTree = DecisionTreeClassifier(random_state=2)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkSXC22wc3UF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "c715b568-ef50-4a81-cf1b-ffb78f89daac"
      },
      "source": [
        "# import DecisionTreeClassifier.\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "\n",
        "my_DecisionTree = DecisionTreeClassifier(random_state=2) \n",
        "my_DecisionTree.fit(A_train, f_train)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=2, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bldSbbFhc3UI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ab2c15a7-331b-40c0-c886-a4f9fb69166f"
      },
      "source": [
        "f_predict = my_DecisionTree.predict(A_test)\n",
        "\n",
        "print(f_predict)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 1 0 0\n",
            " 1 1 0 1 1 0 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciSk1xlac3UK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b1774302-d7e2-4347-ae86-5b2e0c2f56a6"
      },
      "source": [
        "# import accuracy_score from sklearn.metrics\n",
        "from sklearn.metrics import accuracy_score \n",
        "\n",
        "dt_accuracy = accuracy_score(f_test, f_predict)\n",
        "\n",
        "print(dt_accuracy)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmLJJgYkc3UN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#predict Binary model\n",
        "predict_dt = my_DecisionTree.predict(A_test) \n",
        "predict_prob_dt = my_DecisionTree.predict_proba(A_test) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5nOuHeNc3UP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "5540bd70-e7a4-4d1d-82d1-09c4a3742bb1"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "dt_fpr, dt_tpr, thresholds = metrics.roc_curve(f_test, predict_prob_dt[:,1], pos_label=1)\n",
        "print(\"False Positive Rate\")\n",
        "print(dt_fpr)\n",
        "\n",
        "print(\"True Positive Rate\")\n",
        "print(dt_tpr)\n",
        "\n",
        "print(\"Area Under the Curve (AUC)\")\n",
        "DecisionTree_AUC = metrics.auc(dt_fpr, dt_tpr)\n",
        "print(DecisionTree_AUC)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False Positive Rate\n",
            "[0.         0.11764706 1.        ]\n",
            "True Positive Rate\n",
            "[0.         0.85714286 1.        ]\n",
            "Area Under the Curve (AUC)\n",
            "0.8697478991596639\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpgJWxOuc3UQ",
        "colab_type": "text"
      },
      "source": [
        "d- Now, we want to perform “Bagging” based on 29 “base decision tree classifiers”.\n",
        "\n",
        "Note: you should write your own code to perform Bagging (don’t use scikit-learn functions for Bagging!)\n",
        "\n",
        "To do so, you need to perform bootstrapping first. You can write a “for” loop with loop variable i=0...18. In each iteration of the loop, you have to:\n",
        "- make a bootstarp sample of the original “Training” Dataset (build in part(b)) with size\n",
        "of bootstarp_size = 0.8*(Size of the original dataset). You can use the following command to generate a random bootstrap dataset (“i\" is the variable of the loop, so the random_state changes in each iteration):\n",
        "resample(X_train, n_samples = bootstarp_size , random_state=i , replace = True)\n",
        "- Define and train a new base decision tree classifier on this dataset in each iteration:\n",
        "Base_DecisionTree = DecisionTreeClassifier(random_state=2).\n",
        "- Test “this base classifier” on the original “Testing” Dataset build in part(b), and save the prediction results for all testing samples.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2Za0jhSc3UR",
        "colab_type": "text"
      },
      "source": [
        "Then, Perform Voting to make the final decision on each data sample based on the votes of all 29 classifiers. Finally, calculate and report the accuracy and AUC of your Bagging method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veQNfV-9c3UR",
        "colab_type": "text"
      },
      "source": [
        "NOTE: You need to calculate the probability of “malignant cancer” to be able to find AUC and plot the ROC curve. As mentioned in the class, you can consider the average (mean) of the votes as the probability for each sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV_1AxvXc3US",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "840d614d-87ab-4e01-8ce2-8af7656b4446"
      },
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "bootstrap_size = int(0.8*len(A_train))\n",
        "prediction = []\n",
        "result = []\n",
        "\n",
        "for i in range(0,29):\n",
        "    a_bag, f_bag = resample(A_train, f_train, n_samples = bootstrap_size , random_state=i , replace = True)\n",
        "    Base_DecisionTree = DecisionTreeClassifier(random_state=2)\n",
        "    Base_DecisionTree.fit(a_bag, f_bag)\n",
        "    prediction.append(Base_DecisionTree.predict(A_test))\n",
        "    result.append(Base_DecisionTree.predict_proba(A_test))\n",
        "prediction"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "        0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "        0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "        0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "        0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "        0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "        0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "        0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "        0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "        0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "        0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
              "        0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "        0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
              "        0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "        0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "        0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "        0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "        0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "        0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "        0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "        0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
              "        1]),\n",
              " array([0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
              "        1])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppjPys--c3UU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0818d178-e682-4d67-8b33-03e7b6928608"
      },
      "source": [
        "votes = prediction[28]\n",
        "for i in range(0,18):\n",
        "    votes = votes + prediction[i]\n",
        "predictions = []\n",
        "for i in range(votes.size):\n",
        "    if(votes[i] >= 10):\n",
        "        predictions.append(1)\n",
        "    else:\n",
        "        predictions.append(0)\n",
        "bagging_accuracy = accuracy_score(f_test,predictions)\n",
        "print(bagging_accuracy)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9111111111111111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVt7hSf0c3UW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d2f28cf2-fec7-416e-be2b-6cd0543be372"
      },
      "source": [
        "proba = result[28]\n",
        "for i in range(28):\n",
        "    proba += result[i]\n",
        "for i in range(len(proba)):\n",
        "    proba[i] = proba[i]/29\n",
        "    \n",
        "bagging_fpr, bagging_tpr, thresholds = metrics.roc_curve(f_test, proba[:,1], pos_label=1)\n",
        "print(\"False Positive Rate\")\n",
        "print(bagging_fpr)\n",
        "\n",
        "print(\"True Positive Rate\")\n",
        "print(bagging_tpr)\n",
        "\n",
        "print(\"Area Under the Curve (AUC)\")\n",
        "Bagging_AUC = metrics.auc(bagging_fpr, bagging_tpr)\n",
        "print(Bagging_AUC)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False Positive Rate\n",
            "[0.         0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
            " 0.11764706 0.11764706 0.11764706 0.11764706 0.17647059 0.29411765\n",
            " 1.        ]\n",
            "True Positive Rate\n",
            "[0.         0.39285714 0.53571429 0.57142857 0.64285714 0.75\n",
            " 0.78571429 0.85714286 0.92857143 0.96428571 1.         1.\n",
            " 1.        ]\n",
            "Area Under the Curve (AUC)\n",
            "0.9380252100840336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otc33paEc3UX",
        "colab_type": "text"
      },
      "source": [
        "e- Use scikit-learn “Adaboost” classifier to predict Cancer based on the training/testing datasets that you built in part (b). Then, calculate and report the accuracy and AUC of your classifier. Use this command to import and define your classifier:\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "my_AdaBoost = AdaBoostClassifier(n_estimators = 29,random_state=2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zhwc1nofc3UY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "de4ca357-0f1d-468e-f41b-0f56bb3bd512"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "my_AdaBoost = AdaBoostClassifier(n_estimators = 29,random_state=2)\n",
        "my_AdaBoost.fit(A_train, f_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
              "                   n_estimators=29, random_state=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCA6XmtSc3UZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "49e4b57b-1114-4fb0-a77a-a5c78249551d"
      },
      "source": [
        "f_predict = my_AdaBoost.predict(A_test)\n",
        "print(f_predict)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 1 1 0 1 1 1\n",
            " 1 1 0 1 1 0 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF5fhfMpc3Ub",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95039868-95a8-40d8-cc66-7f9bb82f487c"
      },
      "source": [
        "adaboost_accuracy = accuracy_score(f_test, f_predict)\n",
        "print(adaboost_accuracy)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9555555555555556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kNxxmOOc3Uc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#predict Binary model\n",
        "predict_adaboost = my_AdaBoost.predict(A_test) \n",
        "predict_prob_adaboost = my_AdaBoost.predict_proba(A_test) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqfEQvMCc3Ud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "ef654a62-6f66-4fdb-b061-494dc0fc75ff"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "adab_fpr, adab_tpr, thresholds = metrics.roc_curve(f_test, predict_prob_adaboost[:,1], pos_label=1)\n",
        "print(\"False Positive Rate\")\n",
        "print(adab_fpr)\n",
        "\n",
        "print(\"True Positive Rate\")\n",
        "print(adab_tpr)\n",
        "\n",
        "print(\"Area Under the Curve (AUC)\")\n",
        "Adaboost_AUC = metrics.auc(adab_fpr, adab_tpr)\n",
        "print(Adaboost_AUC)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False Positive Rate\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.05882353 0.05882353 0.11764706 0.11764706 0.35294118\n",
            " 0.52941176 1.        ]\n",
            "True Positive Rate\n",
            "[0.         0.03571429 0.10714286 0.21428571 0.25       0.35714286\n",
            " 0.42857143 0.46428571 0.96428571 0.96428571 1.         1.\n",
            " 1.         1.        ]\n",
            "Area Under the Curve (AUC)\n",
            "0.9653361344537815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMqVZ18pc3Uf",
        "colab_type": "text"
      },
      "source": [
        "f- In this section, we use an extremely popular Boosting algorithm called “XGBoost”. This algorithm is not included in sklearn, so you need to install the XGBoost library. Please see this for more infor: https://xgboost.readthedocs.io/en/latest/build.html\n",
        "Mac users can easily install it with “pip install xgboost”.\n",
        "Repeat part (e) with XGBoost. Use this command to import and define your classifier:\n",
        "from xgboost import XGBClassifier\n",
        "my_XGBoost = XGBClassifier(n_estimators = 29,random_state=2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfR55zsLc3Uf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "50753536-e7df-4c17-f0ec-5c44c0e6ad3e"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "my_XGBoost = XGBClassifier(n_estimators = 29,random_state=2)\n",
        "my_XGBoost.fit(A_train, f_train)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=29, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=2,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "togcXlR4c3Ug",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "720d460f-94bc-44cc-8ae5-2c4285a64b37"
      },
      "source": [
        "XGBooat_accuracy = accuracy_score(f_test, f_predict)\n",
        "print(XGBooat_accuracy)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9555555555555556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGGGJh8ec3Ui",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9ccb5e52-3bc8-4247-e9f6-f0ad6c09e1e8"
      },
      "source": [
        "#predict Binary model\n",
        "predict_xgboost = my_XGBoost.predict(A_test) \n",
        "predict_prob_xgboost = my_XGBoost.predict_proba(A_test) \n",
        "\n",
        "predict_xgboost = my_XGBoost.predict(A_test)\n",
        "print(predict_xgboost)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 1 1 0 1 1 1\n",
            " 1 1 0 1 1 0 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KX0uEblc3Uj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f056d645-10b2-48cb-8957-87a8ba50f649"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "xgb_fpr, xgb_tpr, thresholds = metrics.roc_curve(f_test, predict_prob_xgboost[:,1], pos_label=1)\n",
        "print(\"False Positive Rate\")\n",
        "print(xgb_fpr)\n",
        "\n",
        "print(\"True Positive Rate\")\n",
        "print(xgb_tpr)\n",
        "\n",
        "print(\"Area Under the Curve (AUC)\")\n",
        "XGBoost_AUC = metrics.auc(xgb_fpr, xgb_tpr)\n",
        "print(XGBoost_AUC)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False Positive Rate\n",
            "[0.         0.         0.         0.         0.05882353 0.05882353\n",
            " 0.05882353 0.05882353 0.11764706 0.11764706 0.23529412 0.41176471\n",
            " 0.52941176 1.        ]\n",
            "True Positive Rate\n",
            "[0.         0.17857143 0.25       0.35714286 0.42857143 0.5\n",
            " 0.64285714 0.96428571 0.96428571 1.         1.         1.\n",
            " 1.         1.        ]\n",
            "Area Under the Curve (AUC)\n",
            "0.9621848739495799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNGo2M36c3Uk",
        "colab_type": "text"
      },
      "source": [
        "g- Use scikit-learn “Random Forest” classifier to predict Cancer based on the training/testing datasets that you built in part (b). Then, calculate and report the accuracy and AUC of your classifier. Use this command to import and define your classifier:\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "my_RandomForest =\n",
        "RandomForestClassifier(n_estimators = 29, bootstrap = True, random_state=2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL-xBL66c3Uk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "db9b4f32-8479-43de-9c26-7f778e092afd"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "my_RandomForest = RandomForestClassifier(n_estimators = 29, bootstrap = True, random_state=2)\n",
        "my_RandomForest.fit(A_train, f_train)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=29,\n",
              "                       n_jobs=None, oob_score=False, random_state=2, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sax0XS5Cc3Ul",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f579dda2-b0c9-4425-bf20-0ee86a967a56"
      },
      "source": [
        "f_predict = my_RandomForest.predict(A_test)\n",
        "print(f_predict)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1 0 0 0 1 0 1 1 0 1 1 1\n",
            " 1 1 0 1 1 0 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8NTmJoHc3Un",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e04a792-fcfb-4ff2-cb09-79b76cbaaea2"
      },
      "source": [
        "RandomForest_accuracy = accuracy_score(f_test, f_predict)\n",
        "print(RandomForest_accuracy)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9555555555555556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOF5xq6tc3Uo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0cb43e9b-0315-4ab7-9227-8fcaea74d9e4"
      },
      "source": [
        "#predict Binary model\n",
        "predict_rf = my_RandomForest.predict(A_test) \n",
        "predict_prob_rf = my_RandomForest.predict_proba(A_test) \n",
        "\n",
        "predict_rf = my_RandomForest.predict(A_test)\n",
        "print(predict_rf)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1 0 0 0 1 0 1 1 0 1 1 1\n",
            " 1 1 0 1 1 0 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsBKXpCCc3Up",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "9c02c9d1-26ab-4a4e-b474-590b09e8a8fd"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "rf_fpr, rf_tpr, thresholds = metrics.roc_curve(f_test, predict_prob_rf[:,1], pos_label=1)\n",
        "print(\"False Positive Rate\")\n",
        "print(rf_fpr)\n",
        "\n",
        "print(\"True Positive Rate\")\n",
        "print(rf_tpr)\n",
        "\n",
        "print(\"Area Under the Curve (AUC)\")\n",
        "RandomForest_AUC = metrics.auc(rf_fpr, rf_tpr)\n",
        "print(RandomForest_AUC)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False Positive Rate\n",
            "[0.         0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
            " 0.05882353 0.29411765 1.        ]\n",
            "True Positive Rate\n",
            "[0.         0.35714286 0.60714286 0.67857143 0.71428571 0.92857143\n",
            " 1.         1.         1.        ]\n",
            "Area Under the Curve (AUC)\n",
            "0.9516806722689075\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kRCVSLfc3Uq",
        "colab_type": "text"
      },
      "source": [
        "h- Now, plot the ROC curves of your algorithms in parts (c), (d), (e), (f), (g) in a single plane with different colors along with the name of each method. Show the AUCs on the graph as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUp8B0Cjc3Uq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "bf554f53-00ae-43d4-d891-37f99a2f5780"
      },
      "source": [
        "# Import matplotlib.pyplot as plot to generate graphs and plot curves\n",
        "import matplotlib.pyplot as plot \n",
        "%matplotlib inline  \n",
        "plot.figure()\n",
        "\n",
        "plot.plot(dt_fpr, dt_tpr, color='red', lw=2, label='ROC Curve DT (area = %0.2f)' % DecisionTree_AUC)\n",
        "plot.plot(bagging_fpr, bagging_tpr, color='pink', lw=2, label='ROC Curve Bagging (area = %0.2f)' % Bagging_AUC)\n",
        "plot.plot(adab_fpr, adab_tpr, color='blue', lw=2, label='ROC Curve AB (area = %0.2f)' % Adaboost_AUC)\n",
        "plot.plot(xgb_fpr, xgb_tpr, color='black', lw=2, label='ROC Curve XB (area = %0.2f)' % XGBoost_AUC)\n",
        "plot.plot(rf_fpr, rf_tpr, color='green', lw=2, label='ROC Curve RF (area = %0.2f)' % RandomForest_AUC)\n",
        "\n",
        "plot.plot([0, 1], [0, 1], color='blue', lw=1, linestyle='--')\n",
        "\n",
        "# Defining The Range \n",
        "plot.xlim([-0.01, 1.0])\n",
        "plot.ylim([0.0, 1.02])\n",
        "\n",
        "plot.xlabel('FPR')\n",
        "plot.ylabel('TPR')\n",
        "plot.title('ROC')\n",
        "plot.legend(loc=\"lower right\")\n",
        "\n",
        "plot.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERGtUigiIqLVf+IuIs5NlF0fAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5YCdVvcc3Ur",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ef477d9a-3155-4186-9d4b-7913e6248283"
      },
      "source": [
        "print(\"AUC of Decision Tree = \",DecisionTree_AUC)\n",
        "print(\"AUC of Bagging = \",Bagging_AUC)\n",
        "print(\"AUC of Adaboost = \",Adaboost_AUC)\n",
        "print(\"AUC of XGBosst = \",XGBoost_AUC)\n",
        "print(\"AUC of Random Forest = \",RandomForest_AUC)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC of Decision Tree =  0.8697478991596639\n",
            "AUC of Bagging =  0.9380252100840336\n",
            "AUC of Adaboost =  0.9653361344537815\n",
            "AUC of XGBosst =  0.9621848739495799\n",
            "AUC of Random Forest =  0.9516806722689075\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8W-KWkMc3Us",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b50bc543-2f53-48e9-ea38-657dcc6aefe8"
      },
      "source": [
        "print(\"Accuracy of Decision Tree =\",dt_accuracy)\n",
        "print(\"Accuracy of Bagging\",bagging_accuracy)\n",
        "print(\"Accuracy of AdaBoost =\",adaboost_accuracy)\n",
        "print(\"Accuracy of XGBoost =\",XGBooat_accuracy)\n",
        "print(\"Accuracy of Random Forest =\",RandomForest_accuracy)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Decision Tree = 0.8666666666666667\n",
            "Accuracy of Bagging 0.9111111111111111\n",
            "Accuracy of AdaBoost = 0.9555555555555556\n",
            "Accuracy of XGBoost = 0.9555555555555556\n",
            "Accuracy of Random Forest = 0.9555555555555556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjETf6dbc3Ut",
        "colab_type": "text"
      },
      "source": [
        "- Which algorithm is the best w.r.t the AUC value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F75zgtEmc3Ut",
        "colab_type": "text"
      },
      "source": [
        "AdaBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK1V8U4Sc3Uu",
        "colab_type": "text"
      },
      "source": [
        "- Which algorithm is the best w.r.t the Accuracy value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fKC9rfrc3Uu",
        "colab_type": "text"
      },
      "source": [
        "AdaBoost, XGBoost, Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf5udjRMc3Uu",
        "colab_type": "text"
      },
      "source": [
        "- Which algorithm is the best when we want a False Positive Rate of %7?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLybm8Woc3Uv",
        "colab_type": "text"
      },
      "source": [
        "Random Forest"
      ]
    }
  ]
}